{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 2)) (2.2.2)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 3)) (3.8.4)\n",
      "Requirement already satisfied: seaborn in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 4)) (0.13.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 5)) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 2)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 2)) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (3.0.9)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 5)) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 2)) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4860 entries, 0 to 4859\n",
      "Data columns (total 18 columns):\n",
      " #   Column                              Non-Null Count  Dtype  \n",
      "---  ------                              --------------  -----  \n",
      " 0   Id                                  4860 non-null   int64  \n",
      " 1   Altitude                            4860 non-null   int64  \n",
      " 2   Slope_Orientation                   4860 non-null   int64  \n",
      " 3   Slope                               4860 non-null   int64  \n",
      " 4   Horizontal_Distance_To_Water        4860 non-null   int64  \n",
      " 5   Vertical_Distance_To_Water          4860 non-null   int64  \n",
      " 6   Horizontal_Distance_To_Roadways     4860 non-null   int64  \n",
      " 7   Shadow_Index_9h                     4860 non-null   int64  \n",
      " 8   Shadow_Index_12h                    4860 non-null   int64  \n",
      " 9   Shadow_Index_15h                    4860 non-null   int64  \n",
      " 10  Horizontal_Distance_To_Fire_Points  4860 non-null   int64  \n",
      " 11  Canopy_Density                      4860 non-null   float64\n",
      " 12  Rainfall_Summer                     4860 non-null   float64\n",
      " 13  Rainfall_Winter                     4860 non-null   float64\n",
      " 14  Wind_Exposure_Level                 4860 non-null   float64\n",
      " 15  Soil_Type                           4860 non-null   object \n",
      " 16  Wilderness_Area                     4860 non-null   object \n",
      " 17  Vegetation_Type                     4860 non-null   object \n",
      "dtypes: float64(4), int64(11), object(3)\n",
      "memory usage: 683.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "    Id  Altitude  Slope_Orientation  Slope  Horizontal_Distance_To_Water  \\\n",
       " 0  41      2699                347      3                             0   \n",
       " 1  52      2739                323     25                            85   \n",
       " 2  53      2696                 72      2                            30   \n",
       " 3  56      2722                315     24                            30   \n",
       " 4  68      2919                 13     13                            90   \n",
       " \n",
       "    Vertical_Distance_To_Water  Horizontal_Distance_To_Roadways  \\\n",
       " 0                           0                             2096   \n",
       " 1                          43                             3118   \n",
       " 2                           0                             3271   \n",
       " 3                          19                             3216   \n",
       " 4                           6                             5321   \n",
       " \n",
       "    Shadow_Index_9h  Shadow_Index_12h  Shadow_Index_15h  \\\n",
       " 0              213               234               159   \n",
       " 1              149               205               192   \n",
       " 2              222               234               149   \n",
       " 3              148               212               200   \n",
       " 4              207               214               142   \n",
       " \n",
       "    Horizontal_Distance_To_Fire_Points  Canopy_Density  Rainfall_Summer  \\\n",
       " 0                                6853           37.32           282.46   \n",
       " 1                                6219           76.51           182.57   \n",
       " 2                                6071           86.37           374.79   \n",
       " 3                                6132           85.31           364.30   \n",
       " 4                                4060           78.13           303.26   \n",
       " \n",
       "    Rainfall_Winter  Wind_Exposure_Level Soil_Type Wilderness_Area  \\\n",
       " 0           125.22                 6.23   Type_20          Area_1   \n",
       " 1           532.19                30.65   Type_29          Area_1   \n",
       " 2           275.52                59.96   Type_30          Area_1   \n",
       " 3          1182.48                22.21   Type_16          Area_1   \n",
       " 4          1198.69                14.22   Type_29          Area_1   \n",
       " \n",
       "   Vegetation_Type  \n",
       " 0          Type_1  \n",
       " 1          Type_1  \n",
       " 2          Type_1  \n",
       " 3          Type_1  \n",
       " 4          Type_1  )"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install -r requirements.txt\n",
    "# General imports\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Merge the datasets\n",
    "df1 = pd.read_csv('Data_Class_1.csv')\n",
    "df2 = pd.read_csv('Data_Class_3.csv')\n",
    "df3 = pd.read_csv('Data_Class_4.csv')\n",
    "\n",
    "# Concatenate the 3 datasets \n",
    "df = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "\n",
    "df.info(), df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3402, 16), (1458, 16), (3402,), (1458,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Label encode the categorical features\n",
    "label_encoder = LabelEncoder()\n",
    "df['Soil_Type'] = label_encoder.fit_transform(df['Soil_Type'])\n",
    "df['Wilderness_Area'] = label_encoder.fit_transform(df['Wilderness_Area'])\n",
    "df['Vegetation_Type'] = label_encoder.fit_transform(df['Vegetation_Type'])\n",
    "\n",
    "# Split the dataset into features and target variable\n",
    "X = df.drop(columns=['Vegetation_Type', 'Id'])\n",
    "y = df['Vegetation_Type']\n",
    "\n",
    "# Split the dataset into train and test sets for Holdout method\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Check the shape of the resulting datasets\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Results: {'Holdout Accuracy': 0.9300411522633745, 'Holdout F1-Score': 0.9302523274468142, 'CV (k=5) Accuracy': 0.9170781893004115, 'CV (k=5) F1-Score': 0.9175041101126258, 'CV (k=10) Accuracy': 0.9172839506172838, 'CV (k=10) F1-Score': 0.9176676670870935, 'LOOCV Accuracy': 0.9166666666666666, 'LOOCV F1-Score': 0.9166666666666666, 'Bootstrap Accuracy': 0.9266803840877915, 'Bootstrap F1-Score': 0.9269355313087297}\n",
      "LDA Results: {'Holdout Accuracy': 0.9204389574759945, 'Holdout F1-Score': 0.9207568235942984, 'CV (k=5) Accuracy': 0.9028806584362139, 'CV (k=5) F1-Score': 0.9035066027498321, 'CV (k=10) Accuracy': 0.902880658436214, 'CV (k=10) F1-Score': 0.9034669499709981, 'LOOCV Accuracy': 0.9049382716049382, 'LOOCV F1-Score': 0.9049382716049382, 'Bootstrap Accuracy': 0.915, 'Bootstrap F1-Score': 0.9153910992074404}\n",
      "QDA Results: {'Holdout Accuracy': 0.7908093278463649, 'Holdout F1-Score': 0.7800749895936427, 'CV (k=5) Accuracy': 0.7952674897119342, 'CV (k=5) F1-Score': 0.784071811667175, 'CV (k=10) Accuracy': 0.7952674897119342, 'CV (k=10) F1-Score': 0.7837345951049116, 'LOOCV Accuracy': 0.7952674897119342, 'LOOCV F1-Score': 0.7952674897119342, 'Bootstrap Accuracy': 0.7906927297668038, 'Bootstrap F1-Score': 0.7800930100177206}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.model_selection import cross_val_score, LeaveOneOut, StratifiedKFold, train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Label encode the categorical features\n",
    "label_encoder = LabelEncoder()\n",
    "df['Soil_Type'] = label_encoder.fit_transform(df['Soil_Type'])\n",
    "df['Wilderness_Area'] = label_encoder.fit_transform(df['Wilderness_Area'])\n",
    "df['Vegetation_Type'] = label_encoder.fit_transform(df['Vegetation_Type'])\n",
    "\n",
    "# Split the dataset into features and target variable\n",
    "X = df.drop(columns=['Vegetation_Type', 'Id'])\n",
    "y = df['Vegetation_Type']\n",
    "\n",
    "# Split the dataset into train and test sets for Holdout method\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Instantiate models with increased max_iter for Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=20000, random_state=42)\n",
    "lda = LDA()\n",
    "qda = QDA()\n",
    "\n",
    "# Holdout method for Logistic Regression\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "y_pred_log_reg = log_reg.predict(X_test_scaled)\n",
    "log_reg_holdout_acc = accuracy_score(y_test, y_pred_log_reg)\n",
    "log_reg_holdout_f1 = f1_score(y_test, y_pred_log_reg, average='weighted')\n",
    "\n",
    "# Cross Validation (k=5 and k=10) for Logistic Regression\n",
    "kfold_5 = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "kfold_10 = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n",
    "\n",
    "log_reg_cv_5_acc = cross_val_score(log_reg, scaler.fit_transform(X), y, cv=kfold_5, scoring='accuracy').mean()\n",
    "log_reg_cv_5_f1 = cross_val_score(log_reg, scaler.fit_transform(X), y, cv=kfold_5, scoring='f1_weighted').mean()\n",
    "log_reg_cv_10_acc = cross_val_score(log_reg, scaler.fit_transform(X), y, cv=kfold_10, scoring='accuracy').mean()\n",
    "log_reg_cv_10_f1 = cross_val_score(log_reg, scaler.fit_transform(X), y, cv=kfold_10, scoring='f1_weighted').mean()\n",
    "\n",
    "# LOOCV for Logistic Regression\n",
    "loo = LeaveOneOut()\n",
    "log_reg_loocv_acc = cross_val_score(log_reg, scaler.fit_transform(X), y, cv=loo, scoring='accuracy').mean()\n",
    "log_reg_loocv_f1 = cross_val_score(log_reg, scaler.fit_transform(X), y, cv=loo, scoring='f1_weighted').mean()\n",
    "\n",
    "# Bootstrap method for Logistic Regression\n",
    "bootstrap_iterations = 100\n",
    "bootstrap_acc_log_reg = []\n",
    "bootstrap_f1_log_reg = []\n",
    "\n",
    "for i in range(bootstrap_iterations):\n",
    "    X_resampled, y_resampled = resample(X_train_scaled, y_train, random_state=i)\n",
    "    log_reg.fit(X_resampled, y_resampled)\n",
    "    y_pred_bootstrap = log_reg.predict(X_test_scaled)\n",
    "    bootstrap_acc_log_reg.append(accuracy_score(y_test, y_pred_bootstrap))\n",
    "    bootstrap_f1_log_reg.append(f1_score(y_test, y_pred_bootstrap, average='weighted'))\n",
    "\n",
    "log_reg_bootstrap_acc = sum(bootstrap_acc_log_reg) / len(bootstrap_acc_log_reg)\n",
    "log_reg_bootstrap_f1 = sum(bootstrap_f1_log_reg) / len(bootstrap_f1_log_reg)\n",
    "\n",
    "# Store results for Logistic Regression\n",
    "log_reg_results = {\n",
    "    'Holdout Accuracy': log_reg_holdout_acc,\n",
    "    'Holdout F1-Score': log_reg_holdout_f1,\n",
    "    'CV (k=5) Accuracy': log_reg_cv_5_acc,\n",
    "    'CV (k=5) F1-Score': log_reg_cv_5_f1,\n",
    "    'CV (k=10) Accuracy': log_reg_cv_10_acc,\n",
    "    'CV (k=10) F1-Score': log_reg_cv_10_f1,\n",
    "    'LOOCV Accuracy': log_reg_loocv_acc,\n",
    "    'LOOCV F1-Score': log_reg_loocv_f1,\n",
    "    'Bootstrap Accuracy': log_reg_bootstrap_acc,\n",
    "    'Bootstrap F1-Score': log_reg_bootstrap_f1\n",
    "}\n",
    "\n",
    "# Apply scaling to LDA and QDA and calculate metrics\n",
    "# LDA\n",
    "lda.fit(X_train_scaled, y_train)\n",
    "y_pred_lda = lda.predict(X_test_scaled)\n",
    "lda_holdout_acc = accuracy_score(y_test, y_pred_lda)\n",
    "lda_holdout_f1 = f1_score(y_test, y_pred_lda, average='weighted')\n",
    "\n",
    "lda_cv_5_acc = cross_val_score(lda, scaler.fit_transform(X), y, cv=kfold_5, scoring='accuracy').mean()\n",
    "lda_cv_5_f1 = cross_val_score(lda, scaler.fit_transform(X), y, cv=kfold_5, scoring='f1_weighted').mean()\n",
    "lda_cv_10_acc = cross_val_score(lda, scaler.fit_transform(X), y, cv=kfold_10, scoring='accuracy').mean()\n",
    "lda_cv_10_f1 = cross_val_score(lda, scaler.fit_transform(X), y, cv=kfold_10, scoring='f1_weighted').mean()\n",
    "\n",
    "lda_loocv_acc = cross_val_score(lda, scaler.fit_transform(X), y, cv=loo, scoring='accuracy').mean()\n",
    "lda_loocv_f1 = cross_val_score(lda, scaler.fit_transform(X), y, cv=loo, scoring='f1_weighted').mean()\n",
    "\n",
    "bootstrap_acc_lda = []\n",
    "bootstrap_f1_lda = []\n",
    "for i in range(bootstrap_iterations):\n",
    "    X_resampled, y_resampled = resample(X_train_scaled, y_train, random_state=i)\n",
    "    lda.fit(X_resampled, y_resampled)\n",
    "    y_pred_bootstrap_lda = lda.predict(X_test_scaled)\n",
    "    bootstrap_acc_lda.append(accuracy_score(y_test, y_pred_bootstrap_lda))\n",
    "    bootstrap_f1_lda.append(f1_score(y_test, y_pred_bootstrap_lda, average='weighted'))\n",
    "\n",
    "lda_bootstrap_acc = sum(bootstrap_acc_lda) / len(bootstrap_acc_lda)\n",
    "lda_bootstrap_f1 = sum(bootstrap_f1_lda) / len(bootstrap_f1_lda)\n",
    "\n",
    "# Store results for LDA\n",
    "lda_results = {\n",
    "    'Holdout Accuracy': lda_holdout_acc,\n",
    "    'Holdout F1-Score': lda_holdout_f1,\n",
    "    'CV (k=5) Accuracy': lda_cv_5_acc,\n",
    "    'CV (k=5) F1-Score': lda_cv_5_f1,\n",
    "    'CV (k=10) Accuracy': lda_cv_10_acc,\n",
    "    'CV (k=10) F1-Score': lda_cv_10_f1,\n",
    "    'LOOCV Accuracy': lda_loocv_acc,\n",
    "    'LOOCV F1-Score': lda_loocv_f1,\n",
    "    'Bootstrap Accuracy': lda_bootstrap_acc,\n",
    "    'Bootstrap F1-Score': lda_bootstrap_f1\n",
    "}\n",
    "\n",
    "# QDA\n",
    "qda.fit(X_train_scaled, y_train)\n",
    "y_pred_qda = qda.predict(X_test_scaled)\n",
    "qda_holdout_acc = accuracy_score(y_test, y_pred_qda)\n",
    "qda_holdout_f1 = f1_score(y_test, y_pred_qda, average='weighted')\n",
    "\n",
    "qda_cv_5_acc = cross_val_score(qda, scaler.fit_transform(X), y, cv=kfold_5, scoring='accuracy').mean()\n",
    "qda_cv_5_f1 = cross_val_score(qda, scaler.fit_transform(X), y, cv=kfold_5, scoring='f1_weighted').mean()\n",
    "qda_cv_10_acc = cross_val_score(qda, scaler.fit_transform(X), y, cv=kfold_10, scoring='accuracy').mean()\n",
    "qda_cv_10_f1 = cross_val_score(qda, scaler.fit_transform(X), y, cv=kfold_10, scoring='f1_weighted').mean()\n",
    "\n",
    "qda_loocv_acc = cross_val_score(qda, scaler.fit_transform(X), y, cv=loo, scoring='accuracy').mean()\n",
    "qda_loocv_f1 = cross_val_score(qda, scaler.fit_transform(X), y, cv=loo, scoring='f1_weighted').mean()\n",
    "\n",
    "bootstrap_acc_qda = []\n",
    "bootstrap_f1_qda = []\n",
    "for i in range(bootstrap_iterations):\n",
    "    X_resampled, y_resampled = resample(X_train_scaled, y_train, random_state=i)\n",
    "    qda.fit(X_resampled, y_resampled)\n",
    "    y_pred_bootstrap_qda = qda.predict(X_test_scaled)\n",
    "    bootstrap_acc_qda.append(accuracy_score(y_test, y_pred_bootstrap_qda))\n",
    "    bootstrap_f1_qda.append(f1_score(y_test, y_pred_bootstrap_qda, average='weighted'))\n",
    "\n",
    "qda_bootstrap_acc = sum(bootstrap_acc_qda) / len(bootstrap_acc_qda)\n",
    "qda_bootstrap_f1 = sum(bootstrap_f1_qda) / len(bootstrap_f1_qda)\n",
    "\n",
    "# Store results for QDA\n",
    "qda_results = {\n",
    "    'Holdout Accuracy': qda_holdout_acc,\n",
    "    'Holdout F1-Score': qda_holdout_f1,\n",
    "    'CV (k=5) Accuracy': qda_cv_5_acc,\n",
    "    'CV (k=5) F1-Score': qda_cv_5_f1,\n",
    "    'CV (k=10) Accuracy': qda_cv_10_acc,\n",
    "    'CV (k=10) F1-Score': qda_cv_10_f1,\n",
    "    'LOOCV Accuracy': qda_loocv_acc,\n",
    "    'LOOCV F1-Score': qda_loocv_f1,\n",
    "    'Bootstrap Accuracy': qda_bootstrap_acc,\n",
    "    'Bootstrap F1-Score': qda_bootstrap_f1\n",
    "}\n",
    "\n",
    "# Final comparison\n",
    "print(\"Logistic Regression Results:\", log_reg_results)\n",
    "print(\"LDA Results:\", lda_results)\n",
    "print(\"QDA Results:\", qda_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best resampling method for Logistic Regression: Holdout F1-Score\n"
     ]
    }
   ],
   "source": [
    "# Determine the best method based on the results for Logistic Regression\n",
    "best_method = max(log_reg_results, key=log_reg_results.get)\n",
    "print(f\"Best resampling method for Logistic Regression: {best_method}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Classifier Results: {'Holdout Accuracy': 0.850480109739369, 'Holdout F1-Score': 0.8475563349336467}\n",
      "Lasso Logistic Regression Results: {'Holdout Accuracy': 0.9279835390946503, 'Holdout F1-Score': 0.9281248633090963}\n",
      "Ridge Logistic Regression Results: {'Holdout Accuracy': 0.9300411522633745, 'Holdout F1-Score': 0.9302523274468142}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier, LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "# Ridge Classifier\n",
    "ridge_clf = RidgeClassifier()\n",
    "ridge_clf.fit(X_train_scaled, y_train)\n",
    "y_pred_ridge = ridge_clf.predict(X_test_scaled)\n",
    "ridge_holdout_acc = accuracy_score(y_test, y_pred_ridge)\n",
    "ridge_holdout_f1 = f1_score(y_test, y_pred_ridge, average='weighted')\n",
    "\n",
    "# Lasso Logistic Regression (penalty='l1')\n",
    "lasso_clf = LogisticRegression(penalty='l1', solver='saga', max_iter=20000, random_state=42)\n",
    "lasso_clf.fit(X_train_scaled, y_train)\n",
    "y_pred_lasso = lasso_clf.predict(X_test_scaled)\n",
    "lasso_holdout_acc = accuracy_score(y_test, y_pred_lasso)\n",
    "lasso_holdout_f1 = f1_score(y_test, y_pred_lasso, average='weighted')\n",
    "\n",
    "# Ridge Logistic Regression (penalty='l2')\n",
    "ridge_logistic_clf = LogisticRegression(penalty='l2', solver='saga', max_iter=20000, random_state=42)\n",
    "ridge_logistic_clf.fit(X_train_scaled, y_train)\n",
    "y_pred_ridge_logistic = ridge_logistic_clf.predict(X_test_scaled)\n",
    "ridge_logistic_holdout_acc = accuracy_score(y_test, y_pred_ridge_logistic)\n",
    "ridge_logistic_holdout_f1 = f1_score(y_test, y_pred_ridge_logistic, average='weighted')\n",
    "\n",
    "# Store results for Ridge and Lasso Logistic Regression\n",
    "ridge_logistic_results = {\n",
    "    'Holdout Accuracy': ridge_logistic_holdout_acc,\n",
    "    'Holdout F1-Score': ridge_logistic_holdout_f1\n",
    "}\n",
    "\n",
    "lasso_logistic_results = {\n",
    "    'Holdout Accuracy': lasso_holdout_acc,\n",
    "    'Holdout F1-Score': lasso_holdout_f1\n",
    "}\n",
    "\n",
    "ridge_classifier_results = {\n",
    "    'Holdout Accuracy': ridge_holdout_acc,\n",
    "    'Holdout F1-Score': ridge_holdout_f1\n",
    "}\n",
    "\n",
    "# Final comparison\n",
    "print(\"Ridge Classifier Results:\", ridge_classifier_results)\n",
    "print(\"Lasso Logistic Regression Results:\", lasso_logistic_results)\n",
    "print(\"Ridge Logistic Regression Results:\", ridge_logistic_results)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
